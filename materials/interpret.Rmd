---
title: How to interpret R output?
subtitle: Data and statistics with R <br> Research methods <br><br>
author: JÃ¼ri Lillemets
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    highlight: default
    theme: yeti
editor_options: 
  chunk_output_type: console
---

```{r setup, include = F}
# Settings
knitr::opts_chunk$set(include = T, eval = T, echo = T, message = T, warning = T, error = T)
```

The data used in the following examples is from the pacakge *agridat*.

```{r}
apples <- agridat::archbold.apple
sorg <- agridat::adugna.sorghum
fus <- agridat::snijders.fusarium
calves <- agridat::urquhart.feedlot
```

# Correlation

```{r}
cor(calves$weight1, calves$weight2, use = 'pairwise.complete.obs', method = 'pearson')
```

Pearson's correlation coefficient between `weight1` and `weight2` is `r round(cor(calves$weight1, calves$weight2, use = 'pairwise.complete.obs', method = 'pearson'), 3)`. This is a strong positive linear relationship.

```{r}
cor(calves$weight1, calves$weight2, use = 'pairwise.complete.obs', method = 'spearman')
```

Spearman's correlation coefficient between `weight1` and `weight2` is `r round(cor(calves$weight1, calves$weight2, use = 'pairwise.complete.obs', method = 'spearman'), 3)`. This is a strong positive monotonic relationship.


# Hypothesis testing

We test null hypothesis $H_{0}$. If we reject it, we accept alternative hypothesis $H_{1}$.

If p-value $\geq 0.05$, then we accept $H_{0}$.

If p-value $\lt 0.05$, then we reject $H_{0}$ and accept $H_{1}$.

# T-test

## Compare mean of one group to constant

$H_{0}:$ Mean of group is equal to a constant.  
$H_{1}:$ Mean of group is different from a constant.

Is the mean yield of *Golden* apples 160 g/tree?

```{r}
t.test(apples$yield[apples$gen == 'Golden'], mu = 160)
```

P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that the mean yield of Golden apples is not 160 kg/tree.

## Compare means of two groups

$H_{0}:$ Means of groups are equal.  
$H_{1}:$ Means of groups are different.

Is there a difference between the means yields of *Golden* and *Redspur* apple trees?

```{r}
levels(apples$gen)
t.test(yield ~ gen, apples)
```

P-value is greater than 0.05. We thus accept $H_{0}$ that there is no difference between the mean yields of Golden and Redspur.

## Test if mean value is higher than a constant

$H_{0}:$ Mean of group is lower or equal to constant.  
$H_{1}:$ Mean of group is higher than constant.

Is the yield of *Golden* apple trees more than 130 kg/tree?

``` {r}
t.test(apples$yield[apples$gen == 'Golden'], mu = 130, alternative = 'greater')
```

P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that the mean yield of Golden apples is higher than 130 kg/tree.

## Test if mean value of a group is lower than mean value of another group

$H_{0}:$ Mean of 1st group is lower or equal to the mean of 2nd group.  
$H_{1}:$ Mean of 1st group is higher than the mean of 2nd group.

Is mean yield of *Golden* apple trees higher than mean yield of *Redspur* apple trees?

``` {r}
levels(apples$gen)
t.test(yield ~ gen, apples, alternative = 'greater')
```

First group is *Golden* and second group is *Redspur*. P-value is greater than 0.05. We thus accept $H_{0}$ that mean of *Golden* is lower or equal to the mean of *Redspur*.

# Anova

$H_{0}$: Means of all groups are equal.   
$H_{1}$: Mean of at least one group is different from others.

Is mean yield different among locations? Does the mean yield depend on location?

```{r}
sorg <- sorg[sorg$year == 2004, ] # To have independent observations
aggregate(yield ~ loc, sorg, mean)
summary(aov(yield ~ loc, sorg))
```

We compare the means of 3 locations. P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that the mean yield in least one of the locations is different from others.

# Wilcoxon rank sum test

## Compare distributions of two groups

$H_{0}$: Distributions of samples are the same.  
$H_{1}$: Distributions of samples are different.

Are the infection rate (`y`) values differently distributed for strain *F39* compared to other strains?

```{r}
wilcox.test(y ~ fus$strain == 'F39', fus)
```

P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that distribution of infection rate (`y`) of strain *F39* is different than distribution of infection rate (`y`) of other strains.

## Test if median of a group is greater than median of another group

$H_{0}$: Median of 1st group is less than or equal to median of 2nd group.  
$H_{1}$: Median of from 2nd group is greater than median of 2nd group.  

Is the median infection rate (`y`) higher for strain *F39* compared to other strains?

```{r}
wilcox.test(fus$y[fus$strain == 'F39'], fus$y[fus$strain != 'F39'], alternative = 'greater')
```

P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that median of infection rate (`y`) of strain *F39* is higher than median of infection rate (`y`) of other strains.

# KS-test

$H_{0}$: Distributions of both samples are the same.  
$H_{1}$: Distributions of samples are different.

Are the infection rate (`y`) values differently distributed for strain *F39* compared to other strains?

```{r}
ks.test(fus$y[fus$strain == 'F39'], fus$y[fus$strain != 'F39'])
```

P-value is less than 0.05. We thus reject $H_{0}$ and accept the $H_{1}$ that distribution of infection rate (`y`) of strain *F39* is different than distribution of infection rate (`y`) of other strains.

# Ordinary least squares (OLS)

```{r}
wtMod <- lm(weight2 ~ weight1, calves)
summary(wtMod)
```

$$weight2_{i} = `r round(wtMod$coef[[1]], 3)` + `r round(wtMod$coef[[2]], 3)` * weight1_{i} + \varepsilon_{i}$$

When `weight1` is 0, `weight2` is **`r round(wtMod$coef[[1]], 3)`**.

When `weight1` increases by 1 unit, `weight2` increases by **`r round(wtMod$coef[[2]], 3)`** units.

The model explains **`r round(summary(wtMod)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtMod)$r.squared * 100)` percent.

## Log-linear model

```{r}
wtModLogLin <- lm(log(weight2) ~ weight1, calves)
summary(wtModLogLin)
```

$$log(weight2_{i}) = `r round(wtModLogLin$coef[[1]], 3)` + `r round(wtModLogLin$coef[[2]], 3)` * weight1_{i} + \varepsilon_{i}$$

When `weight1` increases by 1 unit, `weight2` increases by `r round(wtModLogLin$coef[[2]], 6)` * 100 = **`r round(wtModLogLin$coef[[2]] * 100, 3)`** percent.

The model explains **`r round(summary(wtModLogLin)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtModLogLin)$r.squared * 100)` percent.

## Linear-log model

```{r}
wtModLinLog <- lm(weight2 ~ log(weight1), calves)
summary(wtModLinLog )
```

$$weight2_{i} = `r round(wtModLinLog$coef[[1]], 3)` + `r round(wtModLinLog$coef[[2]], 3)` * log(weight1_{i}) + \varepsilon_{i}$$

When `weight1` increases by 1 per cent, `weight2` increases by `r round(wtModLinLog$coef[[2]], 3)` / 100 = **`r round(wtModLinLog$coef[[2]] / 100, 3)`** units.

The model explains **`r round(summary(wtModLinLog)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtModLinLog)$r.squared * 100)` percent.

## Log-log model

```{r}
wtModLogLog <- lm(log(weight2) ~ log(weight1), calves)
summary(wtModLogLog)
```

$$log(weight2_{i}) = `r round(wtModLogLog$coef[[1]], 3)` + `r round(wtModLogLog$coef[[2]], 3)` * log(weight1_{i}) + \varepsilon_{i}$$

When `weight1` increases by 1 per cent, `weight2` increases by **`r round(wtModLogLog$coef[[2]], 3)`** percent.

The model explains **`r round(summary(wtModLogLog)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtModLogLog)$r.squared * 100)` percent.

## Polynomial model

```{r}
wtModSq <- lm(weight2 ~ weight1 + I(weight1^2), calves)
summary(wtModSq)
```

$$weight2_{i} = `r round(wtModSq$coef[[1]], 3)` + `r round(wtModSq$coef[[2]], 3)` * weight1_{i} + `r round(wtModSq$coef[[3]], 3)` * weight1_{i}^{2} + \varepsilon_{i}$$

None of the coefficients are statistically significant(ly different from 0). Since we `weight1` has more than one coefficient, it would be difficult to interpret anyway.

The model explains **`r round(summary(wtModSq)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtModSq)$r.squared * 100)` percent.

## Factor variables in model

```{r}
calves$diet <- factor(calves$diet, levels = c('Low', 'Medium', 'High'))
wtModFac <- lm(weight2 ~ weight1 + diet, calves)
summary(wtModFac)
levels(calves$diet)
```

The first factor level (*`r levels(calves$diet)[1]`*) is the base. All other factor values are compared against this base value.

When `weight1` is 0 and `diet` is *`r levels(calves$diet)[1]`*, `weight2` is **`r round(wtModFac$coef[[1]], 3)`**.

When `weight1` increases by 1 unit, `weight2` increases by **`r round(wtModFac$coef[[2]], 3)`** units.

When `diet` is *Medium*, `weight2` is lower by **`r abs(round(wtModFac$coef[[3]], 3))`** units compared to when `diet` is *`r levels(calves$diet)[1]`*.

When `diet` is *High*, `weight2` is no different compared to when `diet` is *`r levels(calves$diet)[1]`*. This is because the coefficient is not statistically significant(ly different from 0).

The model explains **`r round(summary(wtModFac)$r.squared, 3)`** of variance of `weight2`. This is `r round(summary(wtModFac)$r.squared * 100)` percent.

## Diagnostics of OLS

### Residuals have equal variance

```{r}
plot(wtMod, 1)
```

There is no pattern. The values and more or less variance of residuals do not depend on the fitted values of `weight2`. We can conclude that residuals do have equal variance.

### Residuals are normally distributed

```{r}
plot(wtMod, 2)
```

Residuals seem to more or less follow the theoretical quantiles (the straight line). We can conclude that residuals are normally distributed.

## Model comparison

$H_{0}:$ 2nd model has the same residual sum of squares (RSS) as 1st model.  
$H_{1}:$ 2nd model has different residual sum of squares (RSS) than 1st model.

```{r}
anova(wtMod, wtModFac)
```

P-value is greater than 0.05. We thus accept $H_{0}$ that 2nd model has the same residual sum of squares (RSS) as 1st model. In other words, model with `diet` added is not better in explaining the variance of `weight2` than the model without it.